{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "1  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "2  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "3  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "5  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "1       3750.0    male  2007  \n",
       "2       3800.0  female  2007  \n",
       "3       3250.0  female  2007  \n",
       "4          NaN     NaN  2007  \n",
       "5       3450.0  female  2007  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./penguins.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 8)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 344 entries, 1 to 344\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      " 7   year               344 non-null    int64  \n",
      "dtypes: float64(4), int64(1), object(3)\n",
      "memory usage: 24.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 제거\n",
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333 entries, 0 to 332\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            333 non-null    object \n",
      " 1   island             333 non-null    object \n",
      " 2   bill_length_mm     333 non-null    float64\n",
      " 3   bill_depth_mm      333 non-null    float64\n",
      " 4   flipper_length_mm  333 non-null    float64\n",
      " 5   body_mass_g        333 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      " 7   year               333 non-null    int64  \n",
      "dtypes: float64(4), int64(1), object(3)\n",
      "memory usage: 20.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "4  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    male  \n",
       "1       3800.0  female  \n",
       "2       3250.0  female  \n",
       "3       3450.0  female  \n",
       "4       3650.0    male  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:,:-1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Biscoe</th>\n",
       "      <th>Dream</th>\n",
       "      <th>Torgersen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Biscoe  Dream  Torgersen\n",
       "0       0      0          1\n",
       "1       0      0          1\n",
       "2       0      0          1\n",
       "3       0      0          1\n",
       "4       0      0          1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical variable into dummy\n",
    "\n",
    "island_dummies = pd.get_dummies(df.island)\n",
    "sex_dummies = pd.get_dummies(df.sex)\n",
    "island_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>Biscoe</th>\n",
       "      <th>Dream</th>\n",
       "      <th>Torgersen</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "4  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "\n",
       "   body_mass_g     sex  Biscoe  Dream  Torgersen  female  male  \n",
       "0       3750.0    male       0      0          1       0     1  \n",
       "1       3800.0  female       0      0          1       1     0  \n",
       "2       3250.0  female       0      0          1       1     0  \n",
       "3       3450.0  female       0      0          1       1     0  \n",
       "4       3650.0    male       0      0          1       0     1  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df,island_dummies,sex_dummies],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>Biscoe</th>\n",
       "      <th>Dream</th>\n",
       "      <th>Torgersen</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "0  Adelie            39.1           18.7              181.0       3750.0   \n",
       "1  Adelie            39.5           17.4              186.0       3800.0   \n",
       "2  Adelie            40.3           18.0              195.0       3250.0   \n",
       "3  Adelie            36.7           19.3              193.0       3450.0   \n",
       "4  Adelie            39.3           20.6              190.0       3650.0   \n",
       "\n",
       "   Biscoe  Dream  Torgersen  female  male  \n",
       "0       0      0          1       0     1  \n",
       "1       0      0          1       1     0  \n",
       "2       0      0          1       1     0  \n",
       "3       0      0          1       1     0  \n",
       "4       0      0          1       0     1  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['island','sex'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 10)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adelie       146\n",
       "Gentoo       119\n",
       "Chinstrap     68\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열 형태를 정수형으로 변환\n",
    "def make_int(s):\n",
    "  if s == 'Adelie':\n",
    "    return 0\n",
    "  elif s == 'Gentoo':\n",
    "    return 1\n",
    "  else:\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species'] = df['species'].apply(make_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>Biscoe</th>\n",
       "      <th>Dream</th>\n",
       "      <th>Torgersen</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "0        0            39.1           18.7              181.0       3750.0   \n",
       "1        0            39.5           17.4              186.0       3800.0   \n",
       "2        0            40.3           18.0              195.0       3250.0   \n",
       "3        0            36.7           19.3              193.0       3450.0   \n",
       "4        0            39.3           20.6              190.0       3650.0   \n",
       "\n",
       "   Biscoe  Dream  Torgersen  female  male  \n",
       "0       0      0          1       0     1  \n",
       "1       0      0          1       1     0  \n",
       "2       0      0          1       1     0  \n",
       "3       0      0          1       1     0  \n",
       "4       0      0          1       0     1  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hold Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "#I. np.set_printoptions의 suppress option을 True로 설정해 주면 0.11234와 같은 형식으로 출력된다. (fixed point notation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,1:].values\n",
    "y = df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  39.1,   18.7,  181. , 3750. ,    0. ,    0. ,    1. ,    0. ,\n",
       "           1. ]),\n",
       " 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0],y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.1,shuffle=True)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train,y_train,test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x train :  (269, 9)\n",
      "Shape of x test :  (34, 9)\n",
      "Shape of x valid :  (30, 9)\n",
      "Shape of y train :  (269,)\n",
      "Shape of y valid :  (30,)\n",
      "Shape of y test :  (34,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of x train : ',x_train.shape)\n",
    "print('Shape of x test : ',x_test.shape)\n",
    "print('Shape of x valid : ',x_valid.shape)\n",
    "\n",
    "print('Shape of y train : ',y_train.shape)\n",
    "print('Shape of y valid : ',y_valid.shape)\n",
    "print('Shape of y test : ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  35.1,   19.4,  193. , 4200. ],\n",
       "       [  48.2,   14.3,  210. , 4600. ],\n",
       "       [  42.8,   18.5,  195. , 4250. ],\n",
       "       ...,\n",
       "       [  39.6,   18.8,  190. , 4600. ],\n",
       "       [  36.8,   18.5,  193. , 3500. ],\n",
       "       [  50.9,   17.9,  196. , 3675. ]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train[:,:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(x_train[:,:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_std = scaler.transform(x_train[:,:-5])\n",
    "x_valid_std = scaler.transform(x_valid[:,:-5])\n",
    "x_test_std = scaler.transform(x_test[:,:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.64849341,  1.18511028, -0.56865214, -0.01992647])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_std[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_std = np.concatenate([x_train_std,x_train[:,-5:]],axis=1)\n",
    "x_valid_std = np.concatenate([x_valid_std,x_valid[:,-5:]],axis=1)\n",
    "x_test_std = np.concatenate([x_test_std,x_test[:,-5:]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.64849341,  1.18511028, -0.56865214, -0.01992647,  0.        ,\n",
       "        0.        ,  1.        ,  0.        ,  1.        ])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_std[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.56432218,  0.92764407, -1.19843568, -0.38333121,  0.        ,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid_std[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.53633777, -0.05072754, -0.84855593, -1.04957325,  0.        ,\n",
       "        0.        ,  1.        ,  1.        ,  0.        ])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_std[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor dataset\n",
    "Pytorch에서 가중치 학습은 실수형으로 진행됨. 그래서 모든 변수를 실수형으로 바꿔주어야 함.\n",
    "\n",
    "그리고 ndarray와 호환이 안되기 때문에 torch tensor type으로 변환 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_std.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_std = torch.tensor(x_train_std,dtype=torch.float32)\n",
    "x_valid_std = torch.tensor(x_valid_std,dtype=torch.float32)\n",
    "x_test_std = torch.tensor(x_test_std,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.6485,  1.1851, -0.5687, -0.0199,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "         1.0000])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_std[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np_x =df.iloc[:,1:].to_numpy()\n",
    "#np_y = df.iloc[:,0].to_numpy()\n",
    "np_x = df.iloc[:,1:].values\n",
    "np_y = df.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#numpy 배열로 부터 tensor를 정의 할 수있음 df는 안됨\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m torch_x_np \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(np_x)\n\u001b[0;32m      3\u001b[0m torch_y_np \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np_y)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "#numpy 배열로 부터 tensor를 정의 할 수있음 df는 안됨, 숫자 자료형만 넣을 수 있음 object는 안됨\n",
    "torch_x_np = torch.from_numpy(np_x)\n",
    "torch_y_np = torch.from_numpy(np_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train.values).long()\n",
    "y_valid = torch.tensor(y_valid.values).long()\n",
    "y_test = torch.tensor(y_test.values).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 0, 2, 2, 1, 2, 0, 1, 1, 1, 0,\n",
       "        0, 1, 0, 1, 2, 2, 1, 0, 2, 0])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.utils.data.DataLoader 와 torch.utils.data.Dataset 의 두 가지 데이터 기본 요소를 제공하여 미리 준비해둔(pre-loaded) 데이터셋 뿐만 아니라 가지고 있는 데이터를 사용할 수 있도록 합니다.<br> Dataset 은 샘플과 정답(label)을 저장하고, DataLoader 는 Dataset 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset\n",
    "train_dataset = TensorDataset(x_train_std,y_train)\n",
    "valid_dataset = TensorDataset(x_valid_std,y_valid)\n",
    "test_dataset = TensorDataset(x_test_std,y_test)\n",
    "\n",
    "# Make dataloader\n",
    "trainloader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "validloader = DataLoader(valid_dataset,batch_size=4)\n",
    "testloader = DataLoader(test_dataset,batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 9])\n",
      "\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "for x,y in trainloader:\n",
    "  print(x.shape)\n",
    "  print()\n",
    "  print(y.shape)\n",
    "  break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom dataset\n",
    "https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "  def __init__(self,x,y):\n",
    "    self.x = x\n",
    "    self.y = y\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    x_value = torch.tensor(self.x[idx],dtype=torch.float32)\n",
    "    y_value = torch.tensor(self.y[idx]).long()\n",
    "    return x_value,y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 2, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0, 0, 1, 2, 0, 0, 0, 0, 1, 1,\n",
       "        0, 1, 0, 2, 2, 1, 0, 0, 1, 1, 2, 1, 1, 0, 1, 1, 0, 0, 1, 0, 2, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2,\n",
       "        1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0, 2, 1, 1, 1, 2, 0, 1, 2, 0,\n",
       "        0, 1, 1, 1, 0, 2, 1, 0, 2, 1, 2, 2, 0, 1, 0, 1, 0, 1, 2, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 1, 1, 1, 0, 2, 1, 1, 0, 0,\n",
       "        0, 0, 1, 2, 2, 0, 2, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 2, 0,\n",
       "        2, 0, 1, 2, 0, 0, 1, 1, 1, 0, 0, 1, 1, 2, 1, 0, 2, 0, 0, 1, 0, 0, 2, 2,\n",
       "        1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 1, 2, 2, 0, 1, 1, 1, 1,\n",
       "        0, 1, 0, 2, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        0, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "valid_dataset = CustomDataset(x_valid, y_valid)\n",
    "test_dataset = CustomDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataloader\n",
    "trainloader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "validloader = DataLoader(valid_dataset,batch_size=4)\n",
    "testloader = DataLoader(test_dataset,batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 9])\n",
      "torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwshi\\AppData\\Local\\Temp\\ipykernel_18572\\608453465.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_value = torch.tensor(self.y[idx]).long()\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "for x,y in trainloader:\n",
    "  print(x.shape)\n",
    "  print(y.shape)\n",
    "  break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "  #자동으로 bias가 추가?\n",
    "  def __init__(self):\n",
    "    super(MyModel,self).__init__()\n",
    "    #super().__init__()\n",
    "    self.linear1 = nn.Linear(9,256)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.linear2 = nn.Linear(256,128)\n",
    "    self.dropout = nn.Dropout(0.2)\n",
    "    self.out = nn.Linear(128,3)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.linear1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.linear2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.dropout(x)\n",
    "    output = self.out(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU 사용 확인\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (linear1): Linear(in_features=9, out_features=256, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (out): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 256]           2,560\n",
      "              ReLU-2                  [-1, 256]               0\n",
      "            Linear-3                  [-1, 128]          32,896\n",
      "              ReLU-4                  [-1, 128]               0\n",
      "           Dropout-5                  [-1, 128]               0\n",
      "            Linear-6                    [-1, 3]             387\n",
      "================================================================\n",
      "Total params: 35,843\n",
      "Trainable params: 35,843\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 0.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,input_size=(9,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function & opimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwshi\\AppData\\Local\\Temp\\ipykernel_18572\\608453465.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_value = torch.tensor(self.y[idx]).long()\n"
     ]
    }
   ],
   "source": [
    "for x, y in trainloader:\n",
    "  sx = x\n",
    "  sy = y\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 9]), torch.Size([32]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sx.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(sx)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -47.6929, -146.2500,   94.9034], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, loss_fn,optimizer, epoch):\n",
    "  # model.train()\n",
    "  print(f'Epoch : {epoch}')\n",
    "  size = len(dataloader.dataset)\n",
    "  total_batch = len(dataloader)\n",
    "  running_loss = 0\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    output = model(X)\n",
    "    loss = loss_fn(output, y)\n",
    "\n",
    "    optimizer.zero_grad() # 이전 경사 값들의 정보를 날림\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Train loss : {loss.item():>7f} [{batch*len(X)}/{size}]')\n",
    "    running_loss += loss.item()\n",
    "  print(f'Average Train loss : {running_loss/total_batch}\\n')\n",
    "  return running_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 단계(loop)에서 최적화는 세단계로 이뤄집니다:\n",
    "- optimizer.zero_grad()를 호출하여 모델 매개변수의 변화도를 재설정합니다. 기본적으로 변화도는 더해지기(add up) 때문에 중복 계산을 막기 위해 반복할 때마다 명시적으로 0으로 설정합니다.\n",
    "\n",
    "- loss.backwards()를 호출하여 예측 손실(prediction loss)을 역전파합니다. PyTorch는 각 매개변수에 대한 손실의 변화도를 저장합니다.\n",
    "\n",
    "- 변화도를 계산한 뒤에는 optimizer.step()을 호출하여 역전파 단계에서 수집된 변화도로 매개변수를 조정합니다.<br>\n",
    "https://tutorials.pytorch.kr/beginner/basics/optimization_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Train loss : 80.524750 [0/269]\n",
      "Train loss : 177.007462 [32/269]\n",
      "Train loss : 102.845001 [64/269]\n",
      "Train loss : 110.967430 [96/269]\n",
      "Train loss : 74.532013 [128/269]\n",
      "Train loss : 64.908936 [160/269]\n",
      "Train loss : 138.022522 [192/269]\n",
      "Train loss : 47.040630 [224/269]\n",
      "Train loss : 59.495651 [104/269]\n",
      "Average Train loss : 95.038266075982\n",
      "\n",
      "Epoch : 1\n",
      "Train loss : 62.753815 [0/269]\n",
      "Train loss : 99.653923 [32/269]\n",
      "Train loss : 55.181713 [64/269]\n",
      "Train loss : 66.625847 [96/269]\n",
      "Train loss : 74.287926 [128/269]\n",
      "Train loss : 70.359627 [160/269]\n",
      "Train loss : 84.498360 [192/269]\n",
      "Train loss : 50.412025 [224/269]\n",
      "Train loss : 49.678955 [104/269]\n",
      "Average Train loss : 68.16135448879666\n",
      "\n",
      "Epoch : 2\n",
      "Train loss : 82.261337 [0/269]\n",
      "Train loss : 65.372261 [32/269]\n",
      "Train loss : 53.049046 [64/269]\n",
      "Train loss : 46.663273 [96/269]\n",
      "Train loss : 54.837337 [128/269]\n",
      "Train loss : 54.190273 [160/269]\n",
      "Train loss : 47.170551 [192/269]\n",
      "Train loss : 34.237358 [224/269]\n",
      "Train loss : 50.308403 [104/269]\n",
      "Average Train loss : 54.23220443725586\n",
      "\n",
      "Epoch : 3\n",
      "Train loss : 51.003651 [0/269]\n",
      "Train loss : 34.536484 [32/269]\n",
      "Train loss : 19.627314 [64/269]\n",
      "Train loss : 23.101807 [96/269]\n",
      "Train loss : 43.657158 [128/269]\n",
      "Train loss : 14.783914 [160/269]\n",
      "Train loss : 13.028384 [192/269]\n",
      "Train loss : 21.776382 [224/269]\n",
      "Train loss : 16.413795 [104/269]\n",
      "Average Train loss : 26.436543146769207\n",
      "\n",
      "Epoch : 4\n",
      "Train loss : 14.417854 [0/269]\n",
      "Train loss : 11.663896 [32/269]\n",
      "Train loss : 29.876789 [64/269]\n",
      "Train loss : 11.688726 [96/269]\n",
      "Train loss : 13.503777 [128/269]\n",
      "Train loss : 9.646366 [160/269]\n",
      "Train loss : 9.122505 [192/269]\n",
      "Train loss : 7.526230 [224/269]\n",
      "Train loss : 10.940711 [104/269]\n",
      "Average Train loss : 13.154094960954454\n",
      "\n",
      "Epoch : 5\n",
      "Train loss : 7.529166 [0/269]\n",
      "Train loss : 9.571597 [32/269]\n",
      "Train loss : 8.169135 [64/269]\n",
      "Train loss : 7.687265 [96/269]\n",
      "Train loss : 4.567668 [128/269]\n",
      "Train loss : 5.459867 [160/269]\n",
      "Train loss : 3.701373 [192/269]\n",
      "Train loss : 5.713020 [224/269]\n",
      "Train loss : 5.084234 [104/269]\n",
      "Average Train loss : 6.387036138110691\n",
      "\n",
      "Epoch : 6\n",
      "Train loss : 2.356818 [0/269]\n",
      "Train loss : 2.626960 [32/269]\n",
      "Train loss : 1.583343 [64/269]\n",
      "Train loss : 1.275767 [96/269]\n",
      "Train loss : 1.659909 [128/269]\n",
      "Train loss : 1.210880 [160/269]\n",
      "Train loss : 1.035273 [192/269]\n",
      "Train loss : 1.064207 [224/269]\n",
      "Train loss : 1.105734 [104/269]\n",
      "Average Train loss : 1.5465434259838529\n",
      "\n",
      "Epoch : 7\n",
      "Train loss : 1.111781 [0/269]\n",
      "Train loss : 1.117095 [32/269]\n",
      "Train loss : 1.090284 [64/269]\n",
      "Train loss : 1.097248 [96/269]\n",
      "Train loss : 1.087889 [128/269]\n",
      "Train loss : 1.092631 [160/269]\n",
      "Train loss : 1.094310 [192/269]\n",
      "Train loss : 1.065108 [224/269]\n",
      "Train loss : 1.087806 [104/269]\n",
      "Average Train loss : 1.0937946637471516\n",
      "\n",
      "Epoch : 8\n",
      "Train loss : 1.099869 [0/269]\n",
      "Train loss : 1.093033 [32/269]\n",
      "Train loss : 1.101161 [64/269]\n",
      "Train loss : 1.089137 [96/269]\n",
      "Train loss : 1.096756 [128/269]\n",
      "Train loss : 1.084800 [160/269]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwshi\\AppData\\Local\\Temp\\ipykernel_18572\\608453465.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_value = torch.tensor(self.y[idx]).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.097481 [192/269]\n",
      "Train loss : 1.095479 [224/269]\n",
      "Train loss : 1.064803 [104/269]\n",
      "Average Train loss : 1.0913909541236029\n",
      "\n",
      "Epoch : 9\n",
      "Train loss : 1.068471 [0/269]\n",
      "Train loss : 1.086928 [32/269]\n",
      "Train loss : 1.102236 [64/269]\n",
      "Train loss : 1.080157 [96/269]\n",
      "Train loss : 1.080778 [128/269]\n",
      "Train loss : 1.117508 [160/269]\n",
      "Train loss : 1.102321 [192/269]\n",
      "Train loss : 1.091990 [224/269]\n",
      "Train loss : 1.106469 [104/269]\n",
      "Average Train loss : 1.0929841068055894\n",
      "\n",
      "Epoch : 10\n",
      "Train loss : 1.098578 [0/269]\n",
      "Train loss : 1.078167 [32/269]\n",
      "Train loss : 1.113272 [64/269]\n",
      "Train loss : 1.084755 [96/269]\n",
      "Train loss : 1.104330 [128/269]\n",
      "Train loss : 1.083030 [160/269]\n",
      "Train loss : 1.090890 [192/269]\n",
      "Train loss : 1.071972 [224/269]\n",
      "Train loss : 1.088188 [104/269]\n",
      "Average Train loss : 1.090353594885932\n",
      "\n",
      "Epoch : 11\n",
      "Train loss : 1.089075 [0/269]\n",
      "Train loss : 1.105448 [32/269]\n",
      "Train loss : 1.093896 [64/269]\n",
      "Train loss : 1.102589 [96/269]\n",
      "Train loss : 1.066933 [128/269]\n",
      "Train loss : 1.090827 [160/269]\n",
      "Train loss : 1.080495 [192/269]\n",
      "Train loss : 1.066836 [224/269]\n",
      "Train loss : 1.131132 [104/269]\n",
      "Average Train loss : 1.091914587550693\n",
      "\n",
      "Epoch : 12\n",
      "Train loss : 1.112335 [0/269]\n",
      "Train loss : 1.090895 [32/269]\n",
      "Train loss : 1.096945 [64/269]\n",
      "Train loss : 1.075272 [96/269]\n",
      "Train loss : 1.067289 [128/269]\n",
      "Train loss : 1.099328 [160/269]\n",
      "Train loss : 1.078029 [192/269]\n",
      "Train loss : 1.088829 [224/269]\n",
      "Train loss : 1.070409 [104/269]\n",
      "Average Train loss : 1.086592197418213\n",
      "\n",
      "Epoch : 13\n",
      "Train loss : 1.073222 [0/269]\n",
      "Train loss : 1.101438 [32/269]\n",
      "Train loss : 1.081667 [64/269]\n",
      "Train loss : 1.096859 [96/269]\n",
      "Train loss : 1.076950 [128/269]\n",
      "Train loss : 1.082503 [160/269]\n",
      "Train loss : 1.086887 [192/269]\n",
      "Train loss : 1.077548 [224/269]\n",
      "Train loss : 1.121090 [104/269]\n",
      "Average Train loss : 1.088684876759847\n",
      "\n",
      "Epoch : 14\n",
      "Train loss : 1.072428 [0/269]\n",
      "Train loss : 1.105978 [32/269]\n",
      "Train loss : 1.076643 [64/269]\n",
      "Train loss : 1.092153 [96/269]\n",
      "Train loss : 1.090028 [128/269]\n",
      "Train loss : 1.074875 [160/269]\n",
      "Train loss : 1.096011 [192/269]\n",
      "Train loss : 1.074920 [224/269]\n",
      "Train loss : 1.081057 [104/269]\n",
      "Average Train loss : 1.0848991605970595\n",
      "\n",
      "Epoch : 15\n",
      "Train loss : 1.090092 [0/269]\n",
      "Train loss : 1.084955 [32/269]\n",
      "Train loss : 1.085024 [64/269]\n",
      "Train loss : 1.105232 [96/269]\n",
      "Train loss : 1.069115 [128/269]\n",
      "Train loss : 1.089518 [160/269]\n",
      "Train loss : 1.063690 [192/269]\n",
      "Train loss : 1.099841 [224/269]\n",
      "Train loss : 1.041872 [104/269]\n",
      "Average Train loss : 1.0810377067989774\n",
      "\n",
      "Epoch : 16\n",
      "Train loss : 1.088965 [0/269]\n",
      "Train loss : 1.114429 [32/269]\n",
      "Train loss : 1.083771 [64/269]\n",
      "Train loss : 1.089100 [96/269]\n",
      "Train loss : 1.062005 [128/269]\n",
      "Train loss : 1.088966 [160/269]\n",
      "Train loss : 1.077089 [192/269]\n",
      "Train loss : 1.062153 [224/269]\n",
      "Train loss : 1.065507 [104/269]\n",
      "Average Train loss : 1.0813316504160564\n",
      "\n",
      "Epoch : 17\n",
      "Train loss : 1.071266 [0/269]\n",
      "Train loss : 1.098534 [32/269]\n",
      "Train loss : 1.066125 [64/269]\n",
      "Train loss : 1.103022 [96/269]\n",
      "Train loss : 1.065139 [128/269]\n",
      "Train loss : 1.069506 [160/269]\n",
      "Train loss : 1.075790 [192/269]\n",
      "Train loss : 1.096923 [224/269]\n",
      "Train loss : 1.091297 [104/269]\n",
      "Average Train loss : 1.0819556315739949\n",
      "\n",
      "Epoch : 18\n",
      "Train loss : 1.093306 [0/269]\n",
      "Train loss : 1.081942 [32/269]\n",
      "Train loss : 1.092381 [64/269]\n",
      "Train loss : 1.070384 [96/269]\n",
      "Train loss : 1.062336 [128/269]\n",
      "Train loss : 1.063049 [160/269]\n",
      "Train loss : 1.083099 [192/269]\n",
      "Train loss : 1.089143 [224/269]\n",
      "Train loss : 1.088226 [104/269]\n",
      "Average Train loss : 1.080429540740119\n",
      "\n",
      "Epoch : 19\n",
      "Train loss : 1.061189 [0/269]\n",
      "Train loss : 1.097012 [32/269]\n",
      "Train loss : 1.109716 [64/269]\n",
      "Train loss : 1.076707 [96/269]\n",
      "Train loss : 1.081957 [128/269]\n",
      "Train loss : 1.070632 [160/269]\n",
      "Train loss : 1.067551 [192/269]\n",
      "Train loss : 1.080519 [224/269]\n",
      "Train loss : 1.041153 [104/269]\n",
      "Average Train loss : 1.0762706332736545\n",
      "\n",
      "Epoch : 20\n",
      "Train loss : 1.084302 [0/269]\n",
      "Train loss : 1.090846 [32/269]\n",
      "Train loss : 1.068064 [64/269]\n",
      "Train loss : 1.051944 [96/269]\n",
      "Train loss : 1.125507 [128/269]\n",
      "Train loss : 1.079808 [160/269]\n",
      "Train loss : 1.068259 [192/269]\n",
      "Train loss : 1.053575 [224/269]\n",
      "Train loss : 1.072090 [104/269]\n",
      "Average Train loss : 1.077155073483785\n",
      "\n",
      "Epoch : 21\n",
      "Train loss : 1.089672 [0/269]\n",
      "Train loss : 1.083015 [32/269]\n",
      "Train loss : 1.093608 [64/269]\n",
      "Train loss : 1.068600 [96/269]\n",
      "Train loss : 1.045209 [128/269]\n",
      "Train loss : 1.073591 [160/269]\n",
      "Train loss : 1.066286 [192/269]\n",
      "Train loss : 1.085771 [224/269]\n",
      "Train loss : 1.088489 [104/269]\n",
      "Average Train loss : 1.0771379603279962\n",
      "\n",
      "Epoch : 22\n",
      "Train loss : 1.080498 [0/269]\n",
      "Train loss : 1.067195 [32/269]\n",
      "Train loss : 1.061612 [64/269]\n",
      "Train loss : 1.053979 [96/269]\n",
      "Train loss : 1.076115 [128/269]\n",
      "Train loss : 1.096396 [160/269]\n",
      "Train loss : 1.090939 [192/269]\n",
      "Train loss : 1.075730 [224/269]\n",
      "Train loss : 1.074503 [104/269]\n",
      "Average Train loss : 1.0752183728747897\n",
      "\n",
      "Epoch : 23\n",
      "Train loss : 1.080907 [0/269]\n",
      "Train loss : 1.079915 [32/269]\n",
      "Train loss : 1.086925 [64/269]\n",
      "Train loss : 1.106881 [96/269]\n",
      "Train loss : 1.059511 [128/269]\n",
      "Train loss : 1.046134 [160/269]\n",
      "Train loss : 1.069411 [192/269]\n",
      "Train loss : 1.068368 [224/269]\n",
      "Train loss : 1.061580 [104/269]\n",
      "Average Train loss : 1.0732923746109009\n",
      "\n",
      "Epoch : 24\n",
      "Train loss : 1.039812 [0/269]\n",
      "Train loss : 1.052944 [32/269]\n",
      "Train loss : 1.090247 [64/269]\n",
      "Train loss : 1.090560 [96/269]\n",
      "Train loss : 1.098253 [128/269]\n",
      "Train loss : 1.109074 [160/269]\n",
      "Train loss : 1.054686 [192/269]\n",
      "Train loss : 1.059900 [224/269]\n",
      "Train loss : 1.046424 [104/269]\n",
      "Average Train loss : 1.0713221629460652\n",
      "\n",
      "Epoch : 25\n",
      "Train loss : 1.097994 [0/269]\n",
      "Train loss : 1.059540 [32/269]\n",
      "Train loss : 1.076059 [64/269]\n",
      "Train loss : 1.072709 [96/269]\n",
      "Train loss : 1.086820 [128/269]\n",
      "Train loss : 1.101124 [160/269]\n",
      "Train loss : 1.027993 [192/269]\n",
      "Train loss : 1.053225 [224/269]\n",
      "Train loss : 1.072567 [104/269]\n",
      "Average Train loss : 1.0720035764906142\n",
      "\n",
      "Epoch : 26\n",
      "Train loss : 1.070040 [0/269]\n",
      "Train loss : 1.051999 [32/269]\n",
      "Train loss : 1.055725 [64/269]\n",
      "Train loss : 1.103646 [96/269]\n",
      "Train loss : 1.085336 [128/269]\n",
      "Train loss : 1.063143 [160/269]\n",
      "Train loss : 1.049706 [192/269]\n",
      "Train loss : 1.088255 [224/269]\n",
      "Train loss : 1.071914 [104/269]\n",
      "Average Train loss : 1.0710848569869995\n",
      "\n",
      "Epoch : 27\n",
      "Train loss : 1.033741 [0/269]\n",
      "Train loss : 1.079061 [32/269]\n",
      "Train loss : 1.090438 [64/269]\n",
      "Train loss : 1.096795 [96/269]\n",
      "Train loss : 1.034952 [128/269]\n",
      "Train loss : 1.092553 [160/269]\n",
      "Train loss : 1.056188 [192/269]\n",
      "Train loss : 1.065171 [224/269]\n",
      "Train loss : 1.098729 [104/269]\n",
      "Average Train loss : 1.0719586610794067\n",
      "\n",
      "Epoch : 28\n",
      "Train loss : 1.076102 [0/269]\n",
      "Train loss : 1.037222 [32/269]\n",
      "Train loss : 1.077785 [64/269]\n",
      "Train loss : 1.088789 [96/269]\n",
      "Train loss : 1.103627 [128/269]\n",
      "Train loss : 1.077366 [160/269]\n",
      "Train loss : 1.012341 [192/269]\n",
      "Train loss : 1.068121 [224/269]\n",
      "Train loss : 1.098186 [104/269]\n",
      "Average Train loss : 1.071059889263577\n",
      "\n",
      "Epoch : 29\n",
      "Train loss : 1.088562 [0/269]\n",
      "Train loss : 1.063993 [32/269]\n",
      "Train loss : 1.058347 [64/269]\n",
      "Train loss : 1.054266 [96/269]\n",
      "Train loss : 1.065264 [128/269]\n",
      "Train loss : 1.061095 [160/269]\n",
      "Train loss : 1.082798 [192/269]\n",
      "Train loss : 1.099473 [224/269]\n",
      "Train loss : 0.998693 [104/269]\n",
      "Average Train loss : 1.06361010339525\n",
      "\n",
      "Epoch : 30\n",
      "Train loss : 1.078525 [0/269]\n",
      "Train loss : 1.030967 [32/269]\n",
      "Train loss : 1.064333 [64/269]\n",
      "Train loss : 1.096695 [96/269]\n",
      "Train loss : 1.038690 [128/269]\n",
      "Train loss : 1.042803 [160/269]\n",
      "Train loss : 1.106756 [192/269]\n",
      "Train loss : 1.063626 [224/269]\n",
      "Train loss : 1.108235 [104/269]\n",
      "Average Train loss : 1.0700700812869601\n",
      "\n",
      "Epoch : 31\n",
      "Train loss : 1.083502 [0/269]\n",
      "Train loss : 1.068868 [32/269]\n",
      "Train loss : 1.036244 [64/269]\n",
      "Train loss : 1.098011 [96/269]\n",
      "Train loss : 1.073085 [128/269]\n",
      "Train loss : 1.073985 [160/269]\n",
      "Train loss : 1.049598 [192/269]\n",
      "Train loss : 1.052308 [224/269]\n",
      "Train loss : 1.055578 [104/269]\n",
      "Average Train loss : 1.0656867292192247\n",
      "\n",
      "Epoch : 32\n",
      "Train loss : 1.051136 [0/269]\n",
      "Train loss : 1.071709 [32/269]\n",
      "Train loss : 1.098864 [64/269]\n",
      "Train loss : 1.061179 [96/269]\n",
      "Train loss : 1.106026 [128/269]\n",
      "Train loss : 1.045694 [160/269]\n",
      "Train loss : 1.049002 [192/269]\n",
      "Train loss : 1.054545 [224/269]\n",
      "Train loss : 1.032409 [104/269]\n",
      "Average Train loss : 1.063395963774787\n",
      "\n",
      "Epoch : 33\n",
      "Train loss : 1.070600 [0/269]\n",
      "Train loss : 1.098054 [32/269]\n",
      "Train loss : 1.067290 [64/269]\n",
      "Train loss : 1.049698 [96/269]\n",
      "Train loss : 1.055200 [128/269]\n",
      "Train loss : 1.032569 [160/269]\n",
      "Train loss : 1.083589 [192/269]\n",
      "Train loss : 1.053920 [224/269]\n",
      "Train loss : 1.082292 [104/269]\n",
      "Average Train loss : 1.0659125645955403\n",
      "\n",
      "Epoch : 34\n",
      "Train loss : 1.043674 [0/269]\n",
      "Train loss : 1.033309 [32/269]\n",
      "Train loss : 1.087152 [64/269]\n",
      "Train loss : 1.037809 [96/269]\n",
      "Train loss : 1.059646 [128/269]\n",
      "Train loss : 1.120245 [160/269]\n",
      "Train loss : 1.031047 [192/269]\n",
      "Train loss : 1.109254 [224/269]\n",
      "Train loss : 1.040524 [104/269]\n",
      "Average Train loss : 1.06251769595676\n",
      "\n",
      "Epoch : 35\n",
      "Train loss : 1.059155 [0/269]\n",
      "Train loss : 1.030727 [32/269]\n",
      "Train loss : 1.064477 [64/269]\n",
      "Train loss : 1.081326 [96/269]\n",
      "Train loss : 1.064245 [128/269]\n",
      "Train loss : 1.052855 [160/269]\n",
      "Train loss : 1.109572 [192/269]\n",
      "Train loss : 1.029993 [224/269]\n",
      "Train loss : 1.095709 [104/269]\n",
      "Average Train loss : 1.065339830186632\n",
      "\n",
      "Epoch : 36\n",
      "Train loss : 1.058188 [0/269]\n",
      "Train loss : 1.040965 [32/269]\n",
      "Train loss : 1.040671 [64/269]\n",
      "Train loss : 1.075175 [96/269]\n",
      "Train loss : 1.051971 [128/269]\n",
      "Train loss : 1.086469 [160/269]\n",
      "Train loss : 1.098320 [192/269]\n",
      "Train loss : 1.069302 [224/269]\n",
      "Train loss : 1.008902 [104/269]\n",
      "Average Train loss : 1.0588847663667467\n",
      "\n",
      "Epoch : 37\n",
      "Train loss : 1.057160 [0/269]\n",
      "Train loss : 1.068437 [32/269]\n",
      "Train loss : 1.040636 [64/269]\n",
      "Train loss : 1.069048 [96/269]\n",
      "Train loss : 1.068996 [128/269]\n",
      "Train loss : 1.115524 [160/269]\n",
      "Train loss : 1.004195 [192/269]\n",
      "Train loss : 1.062126 [224/269]\n",
      "Train loss : 1.079562 [104/269]\n",
      "Average Train loss : 1.0628538926442463\n",
      "\n",
      "Epoch : 38\n",
      "Train loss : 1.087024 [0/269]\n",
      "Train loss : 1.050993 [32/269]\n",
      "Train loss : 1.085789 [64/269]\n",
      "Train loss : 1.074330 [96/269]\n",
      "Train loss : 1.057878 [128/269]\n",
      "Train loss : 1.055017 [160/269]\n",
      "Train loss : 1.055632 [192/269]\n",
      "Train loss : 1.043370 [224/269]\n",
      "Train loss : 1.004549 [104/269]\n",
      "Average Train loss : 1.0571759674284193\n",
      "\n",
      "Epoch : 39\n",
      "Train loss : 1.085448 [0/269]\n",
      "Train loss : 1.032414 [32/269]\n",
      "Train loss : 1.013402 [64/269]\n",
      "Train loss : 1.085286 [96/269]\n",
      "Train loss : 1.061475 [128/269]\n",
      "Train loss : 1.070788 [160/269]\n",
      "Train loss : 1.038526 [192/269]\n",
      "Train loss : 1.099677 [224/269]\n",
      "Train loss : 1.049435 [104/269]\n",
      "Average Train loss : 1.059605532222324\n",
      "\n",
      "Epoch : 40\n",
      "Train loss : 1.043980 [0/269]\n",
      "Train loss : 1.040414 [32/269]\n",
      "Train loss : 1.103172 [64/269]\n",
      "Train loss : 1.053904 [96/269]\n",
      "Train loss : 1.075915 [128/269]\n",
      "Train loss : 1.032230 [160/269]\n",
      "Train loss : 1.063227 [192/269]\n",
      "Train loss : 1.072390 [224/269]\n",
      "Train loss : 1.037787 [104/269]\n",
      "Average Train loss : 1.0581131776173909\n",
      "\n",
      "Epoch : 41\n",
      "Train loss : 1.073193 [0/269]\n",
      "Train loss : 1.071763 [32/269]\n",
      "Train loss : 1.016037 [64/269]\n",
      "Train loss : 1.054486 [96/269]\n",
      "Train loss : 1.064389 [128/269]\n",
      "Train loss : 1.039908 [160/269]\n",
      "Train loss : 1.067222 [192/269]\n",
      "Train loss : 1.074451 [224/269]\n",
      "Train loss : 1.083506 [104/269]\n",
      "Average Train loss : 1.0605504777696397\n",
      "\n",
      "Epoch : 42\n",
      "Train loss : 1.104669 [0/269]\n",
      "Train loss : 1.062940 [32/269]\n",
      "Train loss : 1.031877 [64/269]\n",
      "Train loss : 1.040764 [96/269]\n",
      "Train loss : 1.070261 [128/269]\n",
      "Train loss : 1.056212 [160/269]\n",
      "Train loss : 1.078426 [192/269]\n",
      "Train loss : 1.034649 [224/269]\n",
      "Train loss : 1.024249 [104/269]\n",
      "Average Train loss : 1.0560051997502644\n",
      "\n",
      "Epoch : 43\n",
      "Train loss : 1.040777 [0/269]\n",
      "Train loss : 1.088006 [32/269]\n",
      "Train loss : 1.028524 [64/269]\n",
      "Train loss : 1.038037 [96/269]\n",
      "Train loss : 1.039811 [128/269]\n",
      "Train loss : 1.070499 [160/269]\n",
      "Train loss : 1.053055 [192/269]\n",
      "Train loss : 1.114715 [224/269]\n",
      "Train loss : 1.031745 [104/269]\n",
      "Average Train loss : 1.0561299721399944\n",
      "\n",
      "Epoch : 44\n",
      "Train loss : 1.019562 [0/269]\n",
      "Train loss : 1.066361 [32/269]\n",
      "Train loss : 1.066321 [64/269]\n",
      "Train loss : 1.061985 [96/269]\n",
      "Train loss : 1.049019 [128/269]\n",
      "Train loss : 1.101542 [160/269]\n",
      "Train loss : 1.052459 [192/269]\n",
      "Train loss : 1.019166 [224/269]\n",
      "Train loss : 1.107287 [104/269]\n",
      "Average Train loss : 1.0604112148284912\n",
      "\n",
      "Epoch : 45\n",
      "Train loss : 1.008621 [0/269]\n",
      "Train loss : 1.041844 [32/269]\n",
      "Train loss : 1.115650 [64/269]\n",
      "Train loss : 1.071724 [96/269]\n",
      "Train loss : 1.087984 [128/269]\n",
      "Train loss : 1.043837 [160/269]\n",
      "Train loss : 1.027389 [192/269]\n",
      "Train loss : 1.054371 [224/269]\n",
      "Train loss : 1.058442 [104/269]\n",
      "Average Train loss : 1.0566515392727323\n",
      "\n",
      "Epoch : 46\n",
      "Train loss : 1.085549 [0/269]\n",
      "Train loss : 1.044097 [32/269]\n",
      "Train loss : 1.093842 [64/269]\n",
      "Train loss : 1.031849 [96/269]\n",
      "Train loss : 1.054243 [128/269]\n",
      "Train loss : 1.079772 [160/269]\n",
      "Train loss : 1.012110 [192/269]\n",
      "Train loss : 1.054156 [224/269]\n",
      "Train loss : 1.036841 [104/269]\n",
      "Average Train loss : 1.0547175804773967\n",
      "\n",
      "Epoch : 47\n",
      "Train loss : 1.022885 [0/269]\n",
      "Train loss : 1.019958 [32/269]\n",
      "Train loss : 1.071180 [64/269]\n",
      "Train loss : 1.031070 [96/269]\n",
      "Train loss : 1.071108 [128/269]\n",
      "Train loss : 1.088274 [160/269]\n",
      "Train loss : 1.036508 [192/269]\n",
      "Train loss : 1.120231 [224/269]\n",
      "Train loss : 1.013909 [104/269]\n",
      "Average Train loss : 1.052791436513265\n",
      "\n",
      "Epoch : 48\n",
      "Train loss : 1.079696 [0/269]\n",
      "Train loss : 1.102569 [32/269]\n",
      "Train loss : 1.073977 [64/269]\n",
      "Train loss : 1.012716 [96/269]\n",
      "Train loss : 1.030318 [128/269]\n",
      "Train loss : 1.044820 [160/269]\n",
      "Train loss : 1.021246 [192/269]\n",
      "Train loss : 1.067492 [224/269]\n",
      "Train loss : 1.070060 [104/269]\n",
      "Average Train loss : 1.055876890818278\n",
      "\n",
      "Epoch : 49\n",
      "Train loss : 1.055976 [0/269]\n",
      "Train loss : 1.061605 [32/269]\n",
      "Train loss : 1.058168 [64/269]\n",
      "Train loss : 1.014943 [96/269]\n",
      "Train loss : 1.070523 [128/269]\n",
      "Train loss : 1.040869 [160/269]\n",
      "Train loss : 1.085292 [192/269]\n",
      "Train loss : 1.053466 [224/269]\n",
      "Train loss : 1.041225 [104/269]\n",
      "Average Train loss : 1.0535629855261908\n",
      "\n",
      "Epoch : 50\n",
      "Train loss : 1.014341 [0/269]\n",
      "Train loss : 1.048150 [32/269]\n",
      "Train loss : 1.021753 [64/269]\n",
      "Train loss : 1.068314 [96/269]\n",
      "Train loss : 1.062656 [128/269]\n",
      "Train loss : 1.023242 [160/269]\n",
      "Train loss : 1.087146 [192/269]\n",
      "Train loss : 1.066383 [224/269]\n",
      "Train loss : 1.152233 [104/269]\n",
      "Average Train loss : 1.0604684617784288\n",
      "\n",
      "Epoch : 51\n",
      "Train loss : 1.007674 [0/269]\n",
      "Train loss : 1.037934 [32/269]\n",
      "Train loss : 1.034016 [64/269]\n",
      "Train loss : 1.045295 [96/269]\n",
      "Train loss : 1.085295 [128/269]\n",
      "Train loss : 1.096674 [160/269]\n",
      "Train loss : 1.041194 [192/269]\n",
      "Train loss : 1.104546 [224/269]\n",
      "Train loss : 0.992393 [104/269]\n",
      "Average Train loss : 1.0494468344582453\n",
      "\n",
      "Epoch : 52\n",
      "Train loss : 1.002880 [0/269]\n",
      "Train loss : 1.052897 [32/269]\n",
      "Train loss : 1.086894 [64/269]\n",
      "Train loss : 1.044682 [96/269]\n",
      "Train loss : 1.048722 [128/269]\n",
      "Train loss : 1.069801 [160/269]\n",
      "Train loss : 1.033144 [192/269]\n",
      "Train loss : 1.075408 [224/269]\n",
      "Train loss : 1.077441 [104/269]\n",
      "Average Train loss : 1.0546521875593398\n",
      "\n",
      "Epoch : 53\n",
      "Train loss : 1.071096 [0/269]\n",
      "Train loss : 0.991831 [32/269]\n",
      "Train loss : 1.058382 [64/269]\n",
      "Train loss : 1.075259 [96/269]\n",
      "Train loss : 1.106505 [128/269]\n",
      "Train loss : 1.006967 [160/269]\n",
      "Train loss : 1.021362 [192/269]\n",
      "Train loss : 1.058300 [224/269]\n",
      "Train loss : 1.129822 [104/269]\n",
      "Average Train loss : 1.0577248136202495\n",
      "\n",
      "Epoch : 54\n",
      "Train loss : 1.062775 [0/269]\n",
      "Train loss : 1.026738 [32/269]\n",
      "Train loss : 1.038992 [64/269]\n",
      "Train loss : 0.996081 [96/269]\n",
      "Train loss : 1.154157 [128/269]\n",
      "Train loss : 1.047949 [160/269]\n",
      "Train loss : 1.015220 [192/269]\n",
      "Train loss : 1.060084 [224/269]\n",
      "Train loss : 1.091017 [104/269]\n",
      "Average Train loss : 1.0547791719436646\n",
      "\n",
      "Epoch : 55\n",
      "Train loss : 1.032803 [0/269]\n",
      "Train loss : 1.031837 [32/269]\n",
      "Train loss : 1.065357 [64/269]\n",
      "Train loss : 1.000565 [96/269]\n",
      "Train loss : 1.025353 [128/269]\n",
      "Train loss : 1.101240 [160/269]\n",
      "Train loss : 1.035758 [192/269]\n",
      "Train loss : 1.101294 [224/269]\n",
      "Train loss : 1.104498 [104/269]\n",
      "Average Train loss : 1.0554117891523573\n",
      "\n",
      "Epoch : 56\n",
      "Train loss : 1.053023 [0/269]\n",
      "Train loss : 1.031883 [32/269]\n",
      "Train loss : 1.036820 [64/269]\n",
      "Train loss : 1.036762 [96/269]\n",
      "Train loss : 1.063039 [128/269]\n",
      "Train loss : 1.068585 [160/269]\n",
      "Train loss : 1.015261 [192/269]\n",
      "Train loss : 1.090773 [224/269]\n",
      "Train loss : 1.090585 [104/269]\n",
      "Average Train loss : 1.0540811750623915\n",
      "\n",
      "Epoch : 57\n",
      "Train loss : 1.047153 [0/269]\n",
      "Train loss : 1.047768 [32/269]\n",
      "Train loss : 1.041297 [64/269]\n",
      "Train loss : 1.057857 [96/269]\n",
      "Train loss : 1.025635 [128/269]\n",
      "Train loss : 1.063347 [160/269]\n",
      "Train loss : 1.030585 [192/269]\n",
      "Train loss : 1.079710 [224/269]\n",
      "Train loss : 1.090394 [104/269]\n",
      "Average Train loss : 1.0537494553460016\n",
      "\n",
      "Epoch : 58\n",
      "Train loss : 1.035749 [0/269]\n",
      "Train loss : 1.057762 [32/269]\n",
      "Train loss : 1.074369 [64/269]\n",
      "Train loss : 1.074215 [96/269]\n",
      "Train loss : 1.063277 [128/269]\n",
      "Train loss : 1.019236 [160/269]\n",
      "Train loss : 1.057686 [192/269]\n",
      "Train loss : 1.035673 [224/269]\n",
      "Train loss : 1.022457 [104/269]\n",
      "Average Train loss : 1.0489359431796603\n",
      "\n",
      "Epoch : 59\n",
      "Train loss : 1.007809 [0/269]\n",
      "Train loss : 1.079615 [32/269]\n",
      "Train loss : 1.057473 [64/269]\n",
      "Train loss : 1.063329 [96/269]\n",
      "Train loss : 1.063104 [128/269]\n",
      "Train loss : 1.057361 [160/269]\n",
      "Train loss : 1.040881 [192/269]\n",
      "Train loss : 1.040562 [224/269]\n",
      "Train loss : 1.035420 [104/269]\n",
      "Average Train loss : 1.0495059490203857\n",
      "\n",
      "Epoch : 60\n",
      "Train loss : 1.085292 [0/269]\n",
      "Train loss : 0.984517 [32/269]\n",
      "Train loss : 1.073975 [64/269]\n",
      "Train loss : 1.079449 [96/269]\n",
      "Train loss : 1.001401 [128/269]\n",
      "Train loss : 1.085748 [160/269]\n",
      "Train loss : 1.012201 [192/269]\n",
      "Train loss : 1.079417 [224/269]\n",
      "Train loss : 1.048422 [104/269]\n",
      "Average Train loss : 1.0500469870037503\n",
      "\n",
      "Epoch : 61\n",
      "Train loss : 0.966513 [0/269]\n",
      "Train loss : 1.011842 [32/269]\n",
      "Train loss : 1.079374 [64/269]\n",
      "Train loss : 1.056781 [96/269]\n",
      "Train loss : 1.130616 [128/269]\n",
      "Train loss : 1.050591 [160/269]\n",
      "Train loss : 1.012059 [192/269]\n",
      "Train loss : 1.063451 [224/269]\n",
      "Train loss : 1.118807 [104/269]\n",
      "Average Train loss : 1.054448088010152\n",
      "\n",
      "Epoch : 62\n",
      "Train loss : 1.000219 [0/269]\n",
      "Train loss : 1.022116 [32/269]\n",
      "Train loss : 1.078495 [64/269]\n",
      "Train loss : 1.079956 [96/269]\n",
      "Train loss : 1.068978 [128/269]\n",
      "Train loss : 1.050906 [160/269]\n",
      "Train loss : 1.085465 [192/269]\n",
      "Train loss : 1.027222 [224/269]\n",
      "Train loss : 1.006857 [104/269]\n",
      "Average Train loss : 1.046690477265252\n",
      "\n",
      "Epoch : 63\n",
      "Train loss : 1.062651 [0/269]\n",
      "Train loss : 1.104609 [32/269]\n",
      "Train loss : 1.050753 [64/269]\n",
      "Train loss : 1.033338 [96/269]\n",
      "Train loss : 1.045188 [128/269]\n",
      "Train loss : 1.011124 [160/269]\n",
      "Train loss : 1.061760 [192/269]\n",
      "Train loss : 1.037110 [224/269]\n",
      "Train loss : 1.017761 [104/269]\n",
      "Average Train loss : 1.0471437904569838\n",
      "\n",
      "Epoch : 64\n",
      "Train loss : 1.068089 [0/269]\n",
      "Train loss : 1.008106 [32/269]\n",
      "Train loss : 1.110613 [64/269]\n",
      "Train loss : 1.020824 [96/269]\n",
      "Train loss : 1.049406 [128/269]\n",
      "Train loss : 1.056960 [160/269]\n",
      "Train loss : 1.091146 [192/269]\n",
      "Train loss : 0.992970 [224/269]\n",
      "Train loss : 1.032942 [104/269]\n",
      "Average Train loss : 1.0478952527046204\n",
      "\n",
      "Epoch : 65\n",
      "Train loss : 1.080140 [0/269]\n",
      "Train loss : 1.025802 [32/269]\n",
      "Train loss : 1.062417 [64/269]\n",
      "Train loss : 1.050155 [96/269]\n",
      "Train loss : 1.063648 [128/269]\n",
      "Train loss : 0.991177 [160/269]\n",
      "Train loss : 1.048805 [192/269]\n",
      "Train loss : 1.067883 [224/269]\n",
      "Train loss : 1.046059 [104/269]\n",
      "Average Train loss : 1.0484539800220065\n",
      "\n",
      "Epoch : 66\n",
      "Train loss : 1.045760 [0/269]\n",
      "Train loss : 1.004378 [32/269]\n",
      "Train loss : 1.090012 [64/269]\n",
      "Train loss : 1.013950 [96/269]\n",
      "Train loss : 1.062283 [128/269]\n",
      "Train loss : 1.017998 [160/269]\n",
      "Train loss : 1.091402 [192/269]\n",
      "Train loss : 1.066401 [224/269]\n",
      "Train loss : 1.035510 [104/269]\n",
      "Average Train loss : 1.047521498468187\n",
      "\n",
      "Epoch : 67\n",
      "Train loss : 1.055236 [0/269]\n",
      "Train loss : 1.051130 [32/269]\n",
      "Train loss : 1.032982 [64/269]\n",
      "Train loss : 1.059268 [96/269]\n",
      "Train loss : 1.067755 [128/269]\n",
      "Train loss : 1.020250 [160/269]\n",
      "Train loss : 1.063686 [192/269]\n",
      "Train loss : 1.011550 [224/269]\n",
      "Train loss : 1.103930 [104/269]\n",
      "Average Train loss : 1.0517541699939303\n",
      "\n",
      "Epoch : 68\n",
      "Train loss : 1.008900 [0/269]\n",
      "Train loss : 1.018434 [32/269]\n",
      "Train loss : 1.117049 [64/269]\n",
      "Train loss : 1.018305 [96/269]\n",
      "Train loss : 1.056536 [128/269]\n",
      "Train loss : 1.111606 [160/269]\n",
      "Train loss : 0.981391 [192/269]\n",
      "Train loss : 1.095590 [224/269]\n",
      "Train loss : 0.985841 [104/269]\n",
      "Average Train loss : 1.0437392526202731\n",
      "\n",
      "Epoch : 69\n",
      "Train loss : 1.047521 [0/269]\n",
      "Train loss : 1.023439 [32/269]\n",
      "Train loss : 1.130360 [64/269]\n",
      "Train loss : 1.082365 [96/269]\n",
      "Train loss : 1.030628 [128/269]\n",
      "Train loss : 1.036136 [160/269]\n",
      "Train loss : 1.025015 [192/269]\n",
      "Train loss : 1.049046 [224/269]\n",
      "Train loss : 0.939420 [104/269]\n",
      "Average Train loss : 1.0404364267985027\n",
      "\n",
      "Epoch : 70\n",
      "Train loss : 0.982170 [0/269]\n",
      "Train loss : 1.052863 [32/269]\n",
      "Train loss : 1.017199 [64/269]\n",
      "Train loss : 1.056395 [96/269]\n",
      "Train loss : 1.054447 [128/269]\n",
      "Train loss : 1.024476 [160/269]\n",
      "Train loss : 1.041265 [192/269]\n",
      "Train loss : 1.101334 [224/269]\n",
      "Train loss : 1.169144 [104/269]\n",
      "Average Train loss : 1.0554769900110033\n",
      "\n",
      "Epoch : 71\n",
      "Train loss : 1.046739 [0/269]\n",
      "Train loss : 1.080748 [32/269]\n",
      "Train loss : 1.052770 [64/269]\n",
      "Train loss : 1.043055 [96/269]\n",
      "Train loss : 1.035365 [128/269]\n",
      "Train loss : 1.103156 [160/269]\n",
      "Train loss : 1.012956 [192/269]\n",
      "Train loss : 1.029686 [224/269]\n",
      "Train loss : 0.978056 [104/269]\n",
      "Average Train loss : 1.0425035887294345\n",
      "\n",
      "Epoch : 72\n",
      "Train loss : 1.024028 [0/269]\n",
      "Train loss : 1.091976 [32/269]\n",
      "Train loss : 1.102084 [64/269]\n",
      "Train loss : 1.078555 [96/269]\n",
      "Train loss : 0.999362 [128/269]\n",
      "Train loss : 0.983509 [160/269]\n",
      "Train loss : 1.051557 [192/269]\n",
      "Train loss : 1.031743 [224/269]\n",
      "Train loss : 1.076428 [104/269]\n",
      "Average Train loss : 1.0488045348061457\n",
      "\n",
      "Epoch : 73\n",
      "Train loss : 1.103061 [0/269]\n",
      "Train loss : 0.996546 [32/269]\n",
      "Train loss : 1.072878 [64/269]\n",
      "Train loss : 1.056344 [96/269]\n",
      "Train loss : 1.069981 [128/269]\n",
      "Train loss : 1.026391 [160/269]\n",
      "Train loss : 1.018040 [192/269]\n",
      "Train loss : 0.998829 [224/269]\n",
      "Train loss : 1.123643 [104/269]\n",
      "Average Train loss : 1.0517458452118769\n",
      "\n",
      "Epoch : 74\n",
      "Train loss : 1.028893 [0/269]\n",
      "Train loss : 0.951948 [32/269]\n",
      "Train loss : 1.070079 [64/269]\n",
      "Train loss : 1.094854 [96/269]\n",
      "Train loss : 1.094878 [128/269]\n",
      "Train loss : 1.047998 [160/269]\n",
      "Train loss : 1.034180 [192/269]\n",
      "Train loss : 1.075587 [224/269]\n",
      "Train loss : 0.981176 [104/269]\n",
      "Average Train loss : 1.0421770612398784\n",
      "\n",
      "Epoch : 75\n",
      "Train loss : 1.081145 [0/269]\n",
      "Train loss : 1.003624 [32/269]\n",
      "Train loss : 1.000713 [64/269]\n",
      "Train loss : 1.033952 [96/269]\n",
      "Train loss : 1.081204 [128/269]\n",
      "Train loss : 1.047806 [160/269]\n",
      "Train loss : 1.084166 [192/269]\n",
      "Train loss : 1.039306 [224/269]\n",
      "Train loss : 1.042017 [104/269]\n",
      "Average Train loss : 1.0459926128387451\n",
      "\n",
      "Epoch : 76\n",
      "Train loss : 1.097821 [0/269]\n",
      "Train loss : 1.050200 [32/269]\n",
      "Train loss : 1.047686 [64/269]\n",
      "Train loss : 1.095381 [96/269]\n",
      "Train loss : 1.017139 [128/269]\n",
      "Train loss : 1.059454 [160/269]\n",
      "Train loss : 0.974730 [192/269]\n",
      "Train loss : 1.027992 [224/269]\n",
      "Train loss : 1.041606 [104/269]\n",
      "Average Train loss : 1.0457787844869826\n",
      "\n",
      "Epoch : 77\n",
      "Train loss : 1.053033 [0/269]\n",
      "Train loss : 1.079162 [32/269]\n",
      "Train loss : 1.047518 [64/269]\n",
      "Train loss : 1.063940 [96/269]\n",
      "Train loss : 1.038729 [128/269]\n",
      "Train loss : 1.016798 [160/269]\n",
      "Train loss : 0.993700 [192/269]\n",
      "Train loss : 1.067181 [224/269]\n",
      "Train loss : 1.062999 [104/269]\n",
      "Average Train loss : 1.0470066799057856\n",
      "\n",
      "Epoch : 78\n",
      "Train loss : 1.101294 [0/269]\n",
      "Train loss : 1.047365 [32/269]\n",
      "Train loss : 1.146461 [64/269]\n",
      "Train loss : 1.025458 [96/269]\n",
      "Train loss : 1.020671 [128/269]\n",
      "Train loss : 0.980283 [160/269]\n",
      "Train loss : 0.993189 [192/269]\n",
      "Train loss : 1.032878 [224/269]\n",
      "Train loss : 1.090010 [104/269]\n",
      "Average Train loss : 1.0486231578720941\n",
      "\n",
      "Epoch : 79\n",
      "Train loss : 1.150326 [0/269]\n",
      "Train loss : 1.052709 [32/269]\n",
      "Train loss : 1.009307 [64/269]\n",
      "Train loss : 1.061681 [96/269]\n",
      "Train loss : 1.001807 [128/269]\n",
      "Train loss : 1.065274 [160/269]\n",
      "Train loss : 0.994517 [192/269]\n",
      "Train loss : 1.021669 [224/269]\n",
      "Train loss : 1.063075 [104/269]\n",
      "Average Train loss : 1.0467072592841253\n",
      "\n",
      "Epoch : 80\n",
      "Train loss : 1.076250 [0/269]\n",
      "Train loss : 1.014234 [32/269]\n",
      "Train loss : 1.047056 [64/269]\n",
      "Train loss : 1.023238 [96/269]\n",
      "Train loss : 1.021453 [128/269]\n",
      "Train loss : 1.036088 [160/269]\n",
      "Train loss : 0.986533 [192/269]\n",
      "Train loss : 1.140690 [224/269]\n",
      "Train loss : 1.090005 [104/269]\n",
      "Average Train loss : 1.048394176695082\n",
      "\n",
      "Epoch : 81\n",
      "Train loss : 1.054018 [0/269]\n",
      "Train loss : 1.081867 [32/269]\n",
      "Train loss : 1.026668 [64/269]\n",
      "Train loss : 1.046871 [96/269]\n",
      "Train loss : 1.077959 [128/269]\n",
      "Train loss : 1.083356 [160/269]\n",
      "Train loss : 0.979292 [192/269]\n",
      "Train loss : 1.025194 [224/269]\n",
      "Train loss : 1.013313 [104/269]\n",
      "Average Train loss : 1.0431707965003119\n",
      "\n",
      "Epoch : 82\n",
      "Train loss : 1.042739 [0/269]\n",
      "Train loss : 1.030507 [32/269]\n",
      "Train loss : 1.052178 [64/269]\n",
      "Train loss : 1.046734 [96/269]\n",
      "Train loss : 1.095576 [128/269]\n",
      "Train loss : 1.030365 [160/269]\n",
      "Train loss : 1.038662 [192/269]\n",
      "Train loss : 1.037196 [224/269]\n",
      "Train loss : 1.012885 [104/269]\n",
      "Average Train loss : 1.0429824325773451\n",
      "\n",
      "Epoch : 83\n",
      "Train loss : 1.039739 [0/269]\n",
      "Train loss : 1.101106 [32/269]\n",
      "Train loss : 1.026137 [64/269]\n",
      "Train loss : 1.087640 [96/269]\n",
      "Train loss : 1.067136 [128/269]\n",
      "Train loss : 0.966070 [160/269]\n",
      "Train loss : 1.052134 [192/269]\n",
      "Train loss : 1.042648 [224/269]\n",
      "Train loss : 0.989070 [104/269]\n",
      "Average Train loss : 1.0412978066338434\n",
      "\n",
      "Epoch : 84\n",
      "Train loss : 0.997378 [0/269]\n",
      "Train loss : 1.102855 [32/269]\n",
      "Train loss : 1.082246 [64/269]\n",
      "Train loss : 1.005164 [96/269]\n",
      "Train loss : 1.072630 [128/269]\n",
      "Train loss : 1.040932 [160/269]\n",
      "Train loss : 1.003741 [192/269]\n",
      "Train loss : 1.036680 [224/269]\n",
      "Train loss : 1.087219 [104/269]\n",
      "Average Train loss : 1.0476493702994452\n",
      "\n",
      "Epoch : 85\n",
      "Train loss : 1.061612 [0/269]\n",
      "Train loss : 1.076860 [32/269]\n",
      "Train loss : 1.004795 [64/269]\n",
      "Train loss : 1.025544 [96/269]\n",
      "Train loss : 1.081065 [128/269]\n",
      "Train loss : 0.996322 [160/269]\n",
      "Train loss : 1.057421 [192/269]\n",
      "Train loss : 1.030986 [224/269]\n",
      "Train loss : 1.100910 [104/269]\n",
      "Average Train loss : 1.0483906202846103\n",
      "\n",
      "Epoch : 86\n",
      "Train loss : 1.044893 [0/269]\n",
      "Train loss : 1.093642 [32/269]\n",
      "Train loss : 1.044841 [64/269]\n",
      "Train loss : 1.088099 [96/269]\n",
      "Train loss : 1.053299 [128/269]\n",
      "Train loss : 0.968059 [160/269]\n",
      "Train loss : 1.014067 [192/269]\n",
      "Train loss : 1.057415 [224/269]\n",
      "Train loss : 1.025318 [104/269]\n",
      "Average Train loss : 1.0432925555441115\n",
      "\n",
      "Epoch : 87\n",
      "Train loss : 1.004177 [0/269]\n",
      "Train loss : 1.051770 [32/269]\n",
      "Train loss : 1.013895 [64/269]\n",
      "Train loss : 1.030685 [96/269]\n",
      "Train loss : 1.145884 [128/269]\n",
      "Train loss : 1.077051 [160/269]\n",
      "Train loss : 0.992667 [192/269]\n",
      "Train loss : 1.036213 [224/269]\n",
      "Train loss : 1.052736 [104/269]\n",
      "Average Train loss : 1.0450086726082697\n",
      "\n",
      "Epoch : 88\n",
      "Train loss : 1.067196 [0/269]\n",
      "Train loss : 1.034820 [32/269]\n",
      "Train loss : 0.988157 [64/269]\n",
      "Train loss : 1.051622 [96/269]\n",
      "Train loss : 1.014824 [128/269]\n",
      "Train loss : 1.051580 [160/269]\n",
      "Train loss : 1.126411 [192/269]\n",
      "Train loss : 1.043777 [224/269]\n",
      "Train loss : 0.986231 [104/269]\n",
      "Average Train loss : 1.0405128531985812\n",
      "\n",
      "Epoch : 89\n",
      "Train loss : 0.971009 [0/269]\n",
      "Train loss : 1.068228 [32/269]\n",
      "Train loss : 1.006856 [64/269]\n",
      "Train loss : 1.104233 [96/269]\n",
      "Train loss : 1.034680 [128/269]\n",
      "Train loss : 1.094152 [160/269]\n",
      "Train loss : 1.084024 [192/269]\n",
      "Train loss : 0.965959 [224/269]\n",
      "Train loss : 1.104743 [104/269]\n",
      "Average Train loss : 1.0482093956735399\n",
      "\n",
      "Epoch : 90\n",
      "Train loss : 1.045809 [0/269]\n",
      "Train loss : 0.953685 [32/269]\n",
      "Train loss : 0.998286 [64/269]\n",
      "Train loss : 1.056933 [96/269]\n",
      "Train loss : 1.099814 [128/269]\n",
      "Train loss : 1.067197 [160/269]\n",
      "Train loss : 1.078314 [192/269]\n",
      "Train loss : 1.066476 [224/269]\n",
      "Train loss : 1.010624 [104/269]\n",
      "Average Train loss : 1.0419042905171711\n",
      "\n",
      "Epoch : 91\n",
      "Train loss : 0.960360 [0/269]\n",
      "Train loss : 1.142164 [32/269]\n",
      "Train loss : 1.105293 [64/269]\n",
      "Train loss : 1.013093 [96/269]\n",
      "Train loss : 0.986566 [128/269]\n",
      "Train loss : 1.029109 [160/269]\n",
      "Train loss : 1.098794 [192/269]\n",
      "Train loss : 1.013508 [224/269]\n",
      "Train loss : 1.051237 [104/269]\n",
      "Average Train loss : 1.0444581111272175\n",
      "\n",
      "Epoch : 92\n",
      "Train loss : 0.970730 [0/269]\n",
      "Train loss : 1.115899 [32/269]\n",
      "Train loss : 1.012963 [64/269]\n",
      "Train loss : 1.029094 [96/269]\n",
      "Train loss : 1.045825 [128/269]\n",
      "Train loss : 1.088822 [160/269]\n",
      "Train loss : 1.018385 [192/269]\n",
      "Train loss : 1.023661 [224/269]\n",
      "Train loss : 1.157060 [104/269]\n",
      "Average Train loss : 1.0513820979330275\n",
      "\n",
      "Epoch : 93\n",
      "Train loss : 1.023956 [0/269]\n",
      "Train loss : 1.083560 [32/269]\n",
      "Train loss : 1.061715 [64/269]\n",
      "Train loss : 0.920681 [96/269]\n",
      "Train loss : 1.077934 [128/269]\n",
      "Train loss : 1.040061 [160/269]\n",
      "Train loss : 1.078016 [192/269]\n",
      "Train loss : 1.045367 [224/269]\n",
      "Train loss : 1.090675 [104/269]\n",
      "Average Train loss : 1.0468850003348456\n",
      "\n",
      "Epoch : 94\n",
      "Train loss : 1.018180 [0/269]\n",
      "Train loss : 1.001768 [32/269]\n",
      "Train loss : 1.012755 [64/269]\n",
      "Train loss : 1.072685 [96/269]\n",
      "Train loss : 1.121596 [128/269]\n",
      "Train loss : 1.056370 [160/269]\n",
      "Train loss : 1.007030 [192/269]\n",
      "Train loss : 1.078437 [224/269]\n",
      "Train loss : 0.996826 [104/269]\n",
      "Average Train loss : 1.0406274067031012\n",
      "\n",
      "Epoch : 95\n",
      "Train loss : 1.006976 [0/269]\n",
      "Train loss : 1.067227 [32/269]\n",
      "Train loss : 1.007042 [64/269]\n",
      "Train loss : 1.078226 [96/269]\n",
      "Train loss : 1.017948 [128/269]\n",
      "Train loss : 1.017885 [160/269]\n",
      "Train loss : 1.094646 [192/269]\n",
      "Train loss : 1.045272 [224/269]\n",
      "Train loss : 1.077644 [104/269]\n",
      "Average Train loss : 1.0458738803863525\n",
      "\n",
      "Epoch : 96\n",
      "Train loss : 1.028644 [0/269]\n",
      "Train loss : 1.006753 [32/269]\n",
      "Train loss : 1.056305 [64/269]\n",
      "Train loss : 1.017763 [96/269]\n",
      "Train loss : 1.100186 [128/269]\n",
      "Train loss : 1.083974 [160/269]\n",
      "Train loss : 1.050840 [192/269]\n",
      "Train loss : 1.034109 [224/269]\n",
      "Train loss : 0.968855 [104/269]\n",
      "Average Train loss : 1.0386033521758185\n",
      "\n",
      "Epoch : 97\n",
      "Train loss : 1.094938 [0/269]\n",
      "Train loss : 1.078358 [32/269]\n",
      "Train loss : 0.973416 [64/269]\n",
      "Train loss : 0.951244 [96/269]\n",
      "Train loss : 1.034095 [128/269]\n",
      "Train loss : 1.078385 [160/269]\n",
      "Train loss : 1.039616 [192/269]\n",
      "Train loss : 1.061768 [224/269]\n",
      "Train loss : 1.132203 [104/269]\n",
      "Average Train loss : 1.0493357645140753\n",
      "\n",
      "Epoch : 98\n",
      "Train loss : 1.061751 [0/269]\n",
      "Train loss : 0.978487 [32/269]\n",
      "Train loss : 1.106308 [64/269]\n",
      "Train loss : 1.050721 [96/269]\n",
      "Train loss : 1.072943 [128/269]\n",
      "Train loss : 1.095053 [160/269]\n",
      "Train loss : 1.017230 [192/269]\n",
      "Train loss : 0.945035 [224/269]\n",
      "Train loss : 1.091220 [104/269]\n",
      "Average Train loss : 1.046527624130249\n",
      "\n",
      "Epoch : 99\n",
      "Train loss : 0.983804 [0/269]\n",
      "Train loss : 1.033831 [32/269]\n",
      "Train loss : 1.100863 [64/269]\n",
      "Train loss : 1.084108 [96/269]\n",
      "Train loss : 0.989146 [128/269]\n",
      "Train loss : 0.994894 [160/269]\n",
      "Train loss : 1.101282 [192/269]\n",
      "Train loss : 1.033683 [224/269]\n",
      "Train loss : 1.104760 [104/269]\n",
      "Average Train loss : 1.0473745862642925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "  train(model,trainloader,criterion,optimizer,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.1500e+01, 1.8300e+01, 1.9500e+02, 4.3000e+03, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [3.9600e+01, 1.8800e+01, 1.9000e+02, 4.6000e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [5.8000e+01, 1.7800e+01, 1.8100e+02, 3.7000e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [4.2400e+01, 1.7300e+01, 1.8100e+02, 3.6000e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [4.6300e+01, 1.5800e+01, 2.1500e+02, 5.0500e+03, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [4.6700e+01, 1.5300e+01, 2.1900e+02, 5.2000e+03, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [4.6200e+01, 1.4500e+01, 2.0900e+02, 4.8000e+03, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [3.6900e+01, 1.8600e+01, 1.8900e+02, 3.5000e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [5.0900e+01, 1.9100e+01, 1.9600e+02, 3.5500e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [3.5600e+01, 1.7500e+01, 1.9100e+02, 3.1750e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [4.6900e+01, 1.6600e+01, 1.9200e+02, 2.7000e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [4.9600e+01, 1.5000e+01, 2.1600e+02, 4.7500e+03, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [4.5400e+01, 1.4600e+01, 2.1100e+02, 4.8000e+03, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [4.6200e+01, 1.4900e+01, 2.2100e+02, 5.3000e+03, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [4.2600e+01, 1.3700e+01, 2.1300e+02, 4.9500e+03, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [5.0900e+01, 1.7900e+01, 1.9600e+02, 3.6750e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [4.3300e+01, 1.4000e+01, 2.0800e+02, 4.5750e+03, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [5.2000e+01, 1.9000e+01, 1.9700e+02, 4.1500e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [4.3500e+01, 1.4200e+01, 2.2000e+02, 4.7000e+03, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [4.1100e+01, 1.8600e+01, 1.8900e+02, 3.3250e+03, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [4.6700e+01, 1.7900e+01, 1.9500e+02, 3.3000e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [4.2300e+01, 2.1200e+01, 1.9100e+02, 4.1500e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [4.9600e+01, 1.8200e+01, 1.9300e+02, 3.7750e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [4.2500e+01, 2.0700e+01, 1.9700e+02, 4.5000e+03, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [3.6200e+01, 1.7300e+01, 1.8700e+02, 3.3000e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [4.5700e+01, 1.7300e+01, 1.9300e+02, 3.6000e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [3.5500e+01, 1.7500e+01, 1.9000e+02, 3.7000e+03, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [4.5500e+01, 1.3700e+01, 2.1400e+02, 4.6500e+03, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [4.5700e+01, 1.3900e+01, 2.1400e+02, 4.4000e+03, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [3.9500e+01, 1.7800e+01, 1.8800e+02, 3.3000e+03, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "        [4.9300e+01, 1.5700e+01, 2.1700e+02, 5.8500e+03, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [3.6700e+01, 1.9300e+01, 1.9300e+02, 3.4500e+03, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 1.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122],\n",
       "        [ 0.3030,  0.1270, -0.4122]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3030,  0.1270, -0.4122], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output.argmax(1) == sy).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, loss_fn,epoch):\n",
    "  total_batch = len(dataloader)\n",
    "  size = len(dataloader.dataset)\n",
    "  model.eval()\n",
    "  test_loss, correct = 0, 0\n",
    "  # 경사 계산 X\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for X,y in dataloader:\n",
    "      X = X.to(device)\n",
    "      y = y.to(device)\n",
    "\n",
    "      preds = model(X)\n",
    "      loss = loss_fn(preds,y)\n",
    "      correct += (preds.argmax(1) == y).sum().item()\n",
    "      test_loss += loss.item()\n",
    "\n",
    "    test_loss /= total_batch\n",
    "    correct /= size\n",
    "\n",
    "  print(f'Epoch : {epoch} Test Loss : {test_loss}, Test Accuracy : {correct}')\n",
    "\n",
    "  return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 Test Loss : 1.117879942059517, Test Accuracy : 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwshi\\AppData\\Local\\Temp\\ipykernel_18572\\608453465.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_value = torch.tensor(self.y[idx]).long()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.117879942059517"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, validloader, criterion,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
